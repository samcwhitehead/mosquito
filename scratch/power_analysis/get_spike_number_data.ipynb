{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c537d3cf-5f0e-44be-bfce-e12c5b1cb33a",
   "metadata": {},
   "source": [
    "# Notebook to analyze spike count within burst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f37f2-2c76-449d-95b6-b281b07e7908",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10e6ec00-43cd-45e4-a814-c21f3fa3d8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "# from matplotlib import rcParams\n",
    "from mosquito.process_abf import load_processed_data\n",
    "from mosquito.analyze_bursts import run_spike_detection, load_burst_data\n",
    "from mosquito.util import iir_notch_filter, butter_highpass_filter, butter_bandpass_filter, moving_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87d91bd-a8c7-43ff-a13b-cdebbae4d7c7",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1446836c-184d-4c54-acfe-c26bfff2610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spike_num_fraction(spike_df):\n",
    "    \"\"\"\n",
    "    Function to get the distributions of spike numbers per burst from a spike dataframe \n",
    "    (the output of 'mosquito/analyze_bursts/run_spike_detection')\n",
    "\n",
    "    Returns a 2 arrays, with first giving spike number and the second giving\n",
    "    the number of instances of that spike number\n",
    "    \"\"\"\n",
    "    # group by burst index and get spike numbers\n",
    "    tmp = spike_df.groupby(by=['burst_idx']).max()\n",
    "    spike_nums = tmp['peak_num'].values + 1  # add 1 to account for 0 index\n",
    "\n",
    "    # get the counts for the two most frequent spike number values (others are likely errors)\n",
    "    spike_nums_unique, unique_counts = np.unique(spike_nums, return_counts=True)\n",
    "    sort_idx = np.flip(np.argsort(unique_counts))  # flip to get it in descending order\n",
    "    stop_ind = min([2, spike_nums_unique.size])\n",
    "    keep_counts = unique_counts[sort_idx][:stop_ind]  # only take two most frequent values\n",
    "    keep_nums = spike_nums_unique[sort_idx][:stop_ind]\n",
    "\n",
    "    return keep_nums, keep_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "27bf567d-bde0-4186-95d5-dfc118f1c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spike_freq(spike_df, fs=35087):\n",
    "    \"\"\"\n",
    "    Function to get frequency of spikes within bursts\n",
    "    \n",
    "    \"\"\"\n",
    "    # initialize some storage\n",
    "    spike_freqs = list()\n",
    "    \n",
    "    # loop over unique burst values\n",
    "    burst_idx_unique = spike_df['burst_idx'].unique()\n",
    "    for bidx in burst_idx_unique:\n",
    "        # get timing differences between peaks corresponding to current burst\n",
    "        peak_idx_curr = spike_df['peak_idx'].loc[spike_df['burst_idx'] == bidx]\n",
    "        peak_diff_sec = (1/fs)*np.diff(peak_idx_curr)\n",
    "        spike_freqs.append(np.mean(peak_diff_sec)**(-1))\n",
    "\n",
    "    # convert to array\n",
    "    spike_freq_arr = np.asarray(spike_freqs)\n",
    "\n",
    "    # remove nans \n",
    "    nan_idx = np.isnan(spike_freq_arr)\n",
    "    spike_freq_arr = spike_freq_arr[~nan_idx]\n",
    "    \n",
    "    return spike_freq_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea593e62-1dbc-4dec-ace7-94cee49b3271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peak_idx</th>\n",
       "      <th>peak_idx_global</th>\n",
       "      <th>burst_idx</th>\n",
       "      <th>peak_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1085</td>\n",
       "      <td>8810</td>\n",
       "      <td>8749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1178</td>\n",
       "      <td>8903</td>\n",
       "      <td>8749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1264</td>\n",
       "      <td>8989</td>\n",
       "      <td>8749</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1350</td>\n",
       "      <td>9075</td>\n",
       "      <td>8749</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1430</td>\n",
       "      <td>9155</td>\n",
       "      <td>8749</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>1177</td>\n",
       "      <td>3260251</td>\n",
       "      <td>3260098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>1266</td>\n",
       "      <td>3260340</td>\n",
       "      <td>3260098</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>1352</td>\n",
       "      <td>3260426</td>\n",
       "      <td>3260098</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>1439</td>\n",
       "      <td>3260513</td>\n",
       "      <td>3260098</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>1612</td>\n",
       "      <td>3260686</td>\n",
       "      <td>3260098</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1152 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      peak_idx  peak_idx_global  burst_idx  peak_num\n",
       "0         1085             8810       8749         0\n",
       "1         1178             8903       8749         1\n",
       "2         1264             8989       8749         2\n",
       "3         1350             9075       8749         3\n",
       "4         1430             9155       8749         4\n",
       "...        ...              ...        ...       ...\n",
       "1147      1177          3260251    3260098         1\n",
       "1148      1266          3260340    3260098         2\n",
       "1149      1352          3260426    3260098         3\n",
       "1150      1439          3260513    3260098         4\n",
       "1151      1612          3260686    3260098         5\n",
       "\n",
       "[1152 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be58f1-c717-42b8-ad76-d2f8991db01e",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "82182cb8-1a55-492c-bb04-86a6857e719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot params\n",
    "plt.style.use('dark_background')\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=16)    # fontsize of the x and y labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4bb7eec2-a81e-419e-8971-af26a9657cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data files that we want/have spike info for\n",
    "data_files = ['19.1', '19.2', '19.5', '19.6', \n",
    "                  '22.2', '22.4', '22.5', '22.12',\n",
    "                  '23.2', '24.7', '24.8', '26.2',\n",
    "                  '28.0', '28.1', '28.2', '28.9',\n",
    "                  '38.9', '38.10', '38.11']\n",
    "\n",
    "# where to look for data\n",
    "data_root = '/media/sam/SamData/Mosquitoes'\n",
    "save_path = os.path.join(data_root, 'analysis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "405fea63-c8f2-479d-af3d-8cea72434098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to log file (and load)\n",
    "log_path = os.path.join(data_root, 'experiment_log.xlsx')\n",
    "log_df = pd.read_excel(log_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9e80539d-0a4b-4543-810a-9be720740038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we need to run spike detection for data files?\n",
    "run_spike_detect_flag = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dbdc3983-a709-45c6-a5f5-629c6f7f3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling freq\n",
    "fs=35087  # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b9afa6-6a33-4dba-9cc3-f51d08f6afa0",
   "metadata": {},
   "source": [
    "## Get spike number for all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0515fbf-a3ef-4ec1-b2d5-f5fcbca4cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over data files and save spike info\n",
    "if run_spike_detect_flag:\n",
    "        \n",
    "    save_path = '/home/sam/Desktop/temp_bursts'\n",
    "    save_name = 'spike_df.pkl'\n",
    "    \n",
    "    # loop over data files\n",
    "    # get paths to experiment folders\n",
    "    expr_folders = sorted([f for f in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, f)) and f[:2].isdigit()])\n",
    "    expr_folder_inds = [f.split('_')[0] for f in expr_folders]\n",
    "       \n",
    "    # turn data file numbers into paths\n",
    "    for file_str in data_files:\n",
    "        # get experiment and axo number from data file number\n",
    "        expr_num = int(file_str.split('.')[0])\n",
    "        axo_num = int(file_str.split('.')[1])\n",
    "    \n",
    "        # get expr folder matching expr number\n",
    "        expr_folder = expr_folders[expr_folder_inds.index(str(expr_num))]\n",
    "        \n",
    "        # load data\n",
    "        data = load_processed_data(expr_num, axo_num)\n",
    "    \n",
    "        # do spike detection\n",
    "        spike_df = run_spike_detection(data, viz_flag=False)\n",
    "    \n",
    "        # save data\n",
    "        save_folder_search = glob.glob(os.path.join(data_root, expr_folder, f'*{axo_num:04d}'))\n",
    "        if len(save_folder_search) == 1:\n",
    "            save_name_full = os.path.join(save_folder_search[0], save_name)\n",
    "            spike_df.to_pickle(save_name_full)\n",
    "            print(save_name_full)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3ee6e-f5bc-4cec-99bb-0070aedce4de",
   "metadata": {},
   "source": [
    "## Make a dictionary containing spike counts for each fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5468d6b-b029-454b-a13b-d6b092202824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed 19_20240510, 1\n",
      "completed 19_20240510, 2\n",
      "completed 19_20240510, 5\n",
      "completed 19_20240510, 6\n",
      "completed 22_20240516, 2\n",
      "completed 22_20240516, 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/Documents/code/mosquito/.pixi/envs/default/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/sam/Documents/code/mosquito/.pixi/envs/default/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/sam/Documents/code/mosquito/.pixi/envs/default/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/sam/Documents/code/mosquito/.pixi/envs/default/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/sam/Documents/code/mosquito/.pixi/envs/default/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/sam/Documents/code/mosquito/.pixi/envs/default/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed 22_20240516, 5\n",
      "completed 22_20240516, 12\n",
      "completed 23_20240517, 2\n",
      "completed 24_20240520, 7\n",
      "completed 24_20240520, 8\n",
      "completed 26_20240524, 2\n",
      "completed 28_20240529, 0\n",
      "completed 28_20240529, 1\n",
      "completed 28_20240529, 2\n",
      "completed 28_20240529, 9\n",
      "completed 38_20240711, 9\n",
      "completed 38_20240711, 10\n",
      "completed 38_20240711, 11\n"
     ]
    }
   ],
   "source": [
    "# initialize dictionary\n",
    "fly_dict = dict()\n",
    "\n",
    "# intialize with some empty lists\n",
    "fly_dict['expr_num'] = list()\n",
    "fly_dict['axo_num'] = list()\n",
    "fly_dict['muscle_target'] = list()\n",
    "fly_dict['sex'] = list()\n",
    "fly_dict['species'] = list()\n",
    "fly_dict['fly_num'] = list()\n",
    "fly_dict['electrode_num'] = list()\n",
    "fly_dict['spike_nums'] = list()\n",
    "fly_dict['spike_num_counts'] = list()\n",
    "fly_dict['peak_times'] = list()\n",
    "fly_dict['spike_freqs'] = list()\n",
    "\n",
    "# get paths to experiment folders\n",
    "expr_folders = sorted([f for f in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, f)) and f[:2].isdigit()])\n",
    "expr_folder_inds = [f.split('_')[0] for f in expr_folders]\n",
    "   \n",
    "# turn data file numbers into paths\n",
    "for ith, file_str in enumerate(data_files):\n",
    "    # get experiment and axo number from data file number\n",
    "    expr_num = int(file_str.split('.')[0])\n",
    "    axo_num = int(file_str.split('.')[1])\n",
    "\n",
    "    # get expr folder matching expr number\n",
    "    expr_folder = expr_folders[expr_folder_inds.index(str(expr_num))]\n",
    "\n",
    "    # get identifying info from log file\n",
    "    row_idx = (log_df['Day'] == expr_folder) & (log_df['Axo Num'] == axo_num)\n",
    "    muscle_target = log_df.loc[row_idx]['Target Muscle'].values[0]\n",
    "    sex = log_df.loc[row_idx]['Sex'].values[0]\n",
    "    species = log_df.loc[row_idx]['Species'].values[0]\n",
    "    fly_num = log_df.loc[row_idx]['Fly Num'].values[0]\n",
    "    electrode_num = log_df.loc[row_idx]['Electrode Num'].values[0]\n",
    "    \n",
    "    # load and read data\n",
    "    spike_df = load_burst_data(expr_folder, axo_num)\n",
    "\n",
    "    # get spike numbers/counts\n",
    "    spike_nums, spike_num_counts = get_spike_num_fraction(spike_df)\n",
    "    \n",
    "    # get timing of spikes relative to burst onset\n",
    "    peak_times = (1/fs)*(spike_df['peak_idx_global'] - spike_df['burst_idx'])\n",
    "    peak_times = peak_times[peak_times > 0]\n",
    "    \n",
    "    # get overall spike frequency\n",
    "    spike_freqs = get_spike_freq(spike_df, fs=fs)\n",
    "\n",
    "    # append things to dict\n",
    "    fly_dict['expr_num'].append(expr_num)\n",
    "    fly_dict['axo_num'].append(axo_num)\n",
    "    fly_dict['muscle_target'].append(muscle_target)\n",
    "    fly_dict['sex'].append(sex)\n",
    "    fly_dict['species'].append(species)\n",
    "    fly_dict['fly_num'].append(fly_num)\n",
    "    fly_dict['electrode_num'].append(int(electrode_num))\n",
    "    fly_dict['spike_nums'].append(spike_nums)\n",
    "    fly_dict['spike_num_counts'].append(spike_num_counts)\n",
    "    fly_dict['peak_times'].append(peak_times.values)\n",
    "    fly_dict['spike_freqs'].append(spike_freqs)\n",
    "\n",
    "    # print update\n",
    "    print(f'completed {expr_folder}, {axo_num}')\n",
    "    \n",
    "# save results\n",
    "save_name = 'burst_analysis_dict.pkl'\n",
    "save_path_full = os.path.join(save_path, save_name)\n",
    "pickle.dump(fly_dict, open(save_path_full, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d7924-19d6-400c-a2da-415390be033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fb9e45-c40c-4446-aadc-6dd339849f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
